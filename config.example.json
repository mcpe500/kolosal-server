{    "server": {
        "port": "8080",
        "host": "0.0.0.0",
        "idle_timeout": 300,
        "allow_public_access": false,
        "allow_internet_access": false
    },
    "logging": {
        "level": "INFO",
        "file": "",
        "access_log": false
    },
    "auth": {
        "enabled": true,
        "require_api_key": false,
        "api_key_header": "X-API-Key",
        "api_keys": [],
        "rate_limit": {
            "enabled": true,
            "max_requests": 100,
            "window_size": 60
        },
        "cors": {
            "enabled": true,
            "allow_credentials": false,
            "max_age": 86400,
            "allowed_origins": [
                "*"
            ],
            "allowed_methods": [
                "GET",
                "POST",
                "PUT",
                "DELETE",
                "OPTIONS",
                "HEAD",
                "PATCH"
            ],
            "allowed_headers": [
                "Content-Type",
                "Authorization",
                "X-Requested-With",
                "Accept",
                "Origin"
            ]
        }
    },
    "models": [
        {
            "id": "qwen3-0.6b",
            "path": "https://huggingface.co/kolosal/qwen3-0.6b/resolve/main/Qwen3-0.6B-UD-Q4_K_XL.gguf",
            "load_immediately": true,
            "main_gpu_id": 0,
            "inference_engine": "llama-cpu",
            "load_params": {
                "n_ctx": 2048,
                "n_keep": 1024,
                "use_mmap": true,
                "use_mlock": false,
                "n_parallel": 1,
                "cont_batching": true,
                "warmup": false,
                "n_gpu_layers": 100,
                "n_batch": 2048,
                "n_ubatch": 512
            }
        },
        {
            "id": "gpt-3.5-turbo",
            "path": "./models/gpt-3.5-turbo.gguf",
            "load_immediately": false,
            "main_gpu_id": 0,
            "inference_engine": "llama-cuda",
            "load_params": {
                "n_ctx": 4096,
                "n_keep": 2048,
                "use_mmap": true,
                "use_mlock": false,
                "n_parallel": 1,
                "cont_batching": true,
                "warmup": false,
                "n_gpu_layers": 100,
                "n_batch": 2048,
                "n_ubatch": 512
            }
        }
    ],    "features": {
        "health_check": true,
        "metrics": true
    }
}