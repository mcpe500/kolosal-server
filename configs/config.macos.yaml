server:
  port: 8087
  host: 127.0.0.1
  idle_timeout: 60
  allow_public_access: false
  allow_internet_access: false
logging:
  level: INFO
  file: ""
  access_log: false
  quiet_mode: false
  show_request_details: true
auth:
  enabled: false
  require_api_key: false
  api_key_header: X-API-Key
  api_keys: []
  rate_limit:
    enabled: true
    max_requests: 100
    window_size: 60
  cors:
    enabled: true
    allow_credentials: false
    max_age: 86400
    allowed_origins:
      - "*"
    allowed_methods:
      - GET
      - POST
      - PUT
      - DELETE
      - OPTIONS
      - HEAD
      - PATCH
    allowed_headers:
      - Content-Type
      - Authorization
      - X-Requested-With
      - Accept
      - Origin
models: []
inference_engines:
  - name: llama-metal
    library_path: ../lib/libllama-metal.dylib
    version: 1.0.0
    description: Apple Metal GPU inference engine
    load_on_startup: true
default_inference_engine: llama-metal
features:
  health_check: true
  metrics: true
