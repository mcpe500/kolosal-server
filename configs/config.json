{    "server": {
        "port": "8084",
        "host": "0.0.0.0",
        "max_connections": 100,
        "worker_threads": 0,
        "request_timeout": 30,
        "max_request_size": 16777216,
        "idle_timeout": 300,
        "allow_public_access": false,
        "allow_internet_access": false
    },    "logging": {
        "level": "INFO",
        "file": "",
        "access_log": false
    },
    "database": {
        "qdrant": {
            "enabled": true,
            "host": "localhost",
            "port": 6333,
            "collection_name": "documents",
            "default_embedding_model": "text-embedding-3-small",
            "timeout": 30,
            "api_key": "",
            "max_connections": 10,
            "connection_timeout": 5
        }
    },
    "auth": {
        "enabled": false,
        "require_api_key": false,
        "api_key_header": "X-API-Key",
        "api_keys": [],
        "rate_limit": {
            "enabled": false,
            "max_requests": 100,
            "window_size": 60
        },
        "cors": {
            "enabled": true,
            "allow_credentials": false,
            "max_age": 86400,
            "allowed_origins": [
                "*"
            ],
            "allowed_methods": [
                "GET",
                "POST",
                "PUT",
                "DELETE",
                "OPTIONS",
                "HEAD",
                "PATCH"
            ],
            "allowed_headers": [
                "Content-Type",
                "Authorization",
                "X-Requested-With",
                "Accept",
                "Origin"
            ]
        }    },
    "models": [
        {
            "id": "qwen3-0.6b",
            "name": "Qwen 3 0.6B",
            "type": "completion",
            "path": "https://huggingface.co/kolosal/qwen3-0.6b",
            "context_length": 2048,
            "batch_size": 512,
            "gpu_layers": -1,
            "rope_freq_base": 10000.0,
            "rope_freq_scale": 1.0,
            "embedding": false
        },
        {
            "id": "all-minilm-l6-v2",
            "name": "All-MiniLM-L6-v2 Embedding",
            "type": "embedding",
            "path": "https://huggingface.co/second-state/All-MiniLM-L6-v2-Embedding-GGUF",
            "context_length": 512,
            "batch_size": 512,
            "gpu_layers": -1,
            "embedding": true
        }
    ],
    "features": {
        "health_check": true,
        "metrics": false
    }
}
