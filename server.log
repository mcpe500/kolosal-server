[2025-09-19 11:39:33.278] [INFO] Logger configured - Level: INFO, Quiet: false, Details: true
[2025-09-19 11:39:33.279] [INFO] Initializing server on 127.0.0.1:8081 with idle timeout: 60 seconds
[2025-09-19 11:39:33.280] [INFO] NodeManager initialized with idle timeout: 60 seconds.
[2025-09-19 11:39:33.281] [INFO] Configured inference engine: llama-cpu at C:\ProgramData\Kolosal\bin\llama-cpu.dll
[2025-09-19 11:39:33.312] [INFO] Successfully loaded inference engine: llama-cpu
[2025-09-19 11:39:33.312] [INFO] Auto-loaded inference engine: llama-cpu
[2025-09-19 11:39:33.312] [INFO] Configured inference engine: llama-vulkan at C:\ProgramData\Kolosal\bin\llama-vulkan.dll
[2025-09-19 11:39:33.313] [INFO] Engine configuration complete. Configured 2 inference engines.
[2025-09-19 11:39:33.313] [INFO] Configured 2 inference engines:
[2025-09-19 11:39:33.314] [INFO]   - llama-cpu: CPU-based inference engine for GGUF models (loaded)
[2025-09-19 11:39:33.314] [INFO]   - llama-vulkan: Vulkan GPU acceleration engine for GGUF models (available)
[2025-09-19 11:39:33.315] [INFO] Autoscaling thread started.
[2025-09-19 11:39:33.315] [INFO] Rate limiter initialized with default config - Max requests: 100, Window: 60 seconds, Enabled: true
[2025-09-19 11:39:33.316] [INFO] CORS configuration updated - Enabled: true, Origins: 1, Methods: 7, Headers: 5
[2025-09-19 11:39:33.317] [INFO] Authentication middleware initialized with default configuration
[2025-09-19 11:39:33.319] [INFO] Server initialized and listening on 127.0.0.1:8081
[2025-09-19 11:39:33.319] [INFO] Registering routes
[2025-09-19 11:39:33.320] [INFO] ModelsRoute initialized
[2025-09-19 11:39:33.321] [INFO] Auth config route initialized
[2025-09-19 11:39:33.321] [INFO] EmbeddingRoute initialized with completion monitoring
[2025-09-19 11:39:33.322] [INFO] DocumentsRoute initialized
[2025-09-19 11:39:33.322] [INFO] ChunkingService initialized
[2025-09-19 11:39:33.323] [INFO] ChunkingRoute initialized
[2025-09-19 11:39:33.323] [INFO] Routes registered successfully
[2025-09-19 11:39:33.323] [INFO] Rate limiter configuration updated - Max requests: 100, Window: 60 seconds, Enabled: true
[2025-09-19 11:39:33.323] [INFO] Starting server main loop
[2025-09-19 11:39:33.323] [INFO] CORS configuration updated - Enabled: true, Origins: 1, Methods: 7, Headers: 5
[2025-09-19 11:39:33.323] [INFO] Server entering main loop with concurrent request handling
[2025-09-19 11:39:33.324] [INFO] API key configuration updated - Enabled: true, Required: false, Keys count: 0
[2025-09-19 11:39:33.324] [INFO] Authentication configured - Rate Limit: enabled, CORS: enabled, API Keys: optional (0 keys)
[2025-09-19 11:39:33.324] [INFO] Metrics functionality not yet implemented
[2025-09-19 11:39:33.324] [INFO] System metrics monitoring enabled
[2025-09-19 11:39:33.325] [INFO] Loading LLM model 'qwen3-0.6b:UD-Q4_K_XL' at startup (load_immediately=true, engine=llama-vulkan)
[2025-09-19 11:39:33.325] [INFO] Validating model file for engine 'qwen3-0.6b:UD-Q4_K_XL': D:\Works\Genta\codes\kolosal-agent\models\qwen2.5-0.5b-instruct-q4_k_m.gguf
[2025-09-19 11:39:33.326] [INFO] Local model file found. Size: 468.64 MB
[2025-09-19 11:39:33.326] [INFO] Creating llama-vulkan inference engine for ID 'qwen3-0.6b:UD-Q4_K_XL'
[2025-09-19 11:39:33.326] [INFO] Loading llama-vulkan inference engine plugin...
[2025-09-19 11:39:33.365] [INFO] Successfully loaded inference engine: llama-vulkan
[2025-09-19 11:39:33.365] [INFO] Successfully loaded llama-vulkan inference engine plugin
[2025-09-19 11:39:33.365] [INFO] Creating inference engine instance...
[2025-09-19 11:39:33.366] [INFO] Loading model for engine 'qwen3-0.6b:UD-Q4_K_XL' from path: D:\Works\Genta\codes\kolosal-agent\models\qwen2.5-0.5b-instruct-q4_k_m.gguf
[2025-09-19 11:39:34.116] [INFO] Successfully loaded model for engine 'qwen3-0.6b:UD-Q4_K_XL'
[2025-09-19 11:39:34.116] [INFO] Successfully added and loaded engine with ID 'qwen3-0.6b:UD-Q4_K_XL'. Model: D:\Works\Genta\codes\kolosal-agent\models\qwen2.5-0.5b-instruct-q4_k_m.gguf
[2025-09-19 11:39:34.116] [INFO] Model 'qwen3-0.6b:UD-Q4_K_XL' already exists in configuration, updating it
[2025-09-19 11:39:34.117] [INFO] Updated model 'qwen3-0.6b:UD-Q4_K_XL' in configuration
[2025-09-19 11:39:34.117] [INFO] About to save configuration for model 'qwen3-0.6b:UD-Q4_K_XL'
[2025-09-19 11:39:34.117] [INFO] Current config file path in NodeManager: 'C:\Users\Evint\AppData\Roaming\Kolosal\config.yaml'
[2025-09-19 11:39:34.118] [INFO] ServerConfig instance address during model save: 3546093664
[2025-09-19 11:39:34.119] [INFO] saveToCurrentFile called. currentConfigFilePath: 'C:\Users\Evint\AppData\Roaming\Kolosal\config.yaml'
[2025-09-19 11:39:34.120] [INFO] ServerConfig instance address: 140710969677920
[2025-09-19 11:39:34.120] [INFO] Saving to current config file: C:\Users\Evint\AppData\Roaming\Kolosal\config.yaml
[2025-09-19 11:39:34.132] [INFO] Successfully saved model 'qwen3-0.6b:UD-Q4_K_XL' to configuration file
[2025-09-19 11:39:34.133] [INFO] Model 'qwen3-0.6b:UD-Q4_K_XL' loaded successfully
[2025-09-19 11:39:34.134] [INFO] Loading LLM model 'qwen2.5-0.5b-instruct' at startup (load_immediately=true, engine=llama-vulkan)
[2025-09-19 11:39:34.135] [INFO] Validating model file for engine 'qwen2.5-0.5b-instruct': D:\Works\Genta\codes\kolosal-agent\models\qwen2.5-0.5b-instruct-q4_k_m.gguf
[2025-09-19 11:39:34.135] [INFO] Local model file found. Size: 468.64 MB
[2025-09-19 11:39:34.135] [INFO] Creating llama-vulkan inference engine for ID 'qwen2.5-0.5b-instruct'
[2025-09-19 11:39:34.136] [INFO] Creating inference engine instance...
[2025-09-19 11:39:34.136] [INFO] Loading model for engine 'qwen2.5-0.5b-instruct' from path: D:\Works\Genta\codes\kolosal-agent\models\qwen2.5-0.5b-instruct-q4_k_m.gguf
[2025-09-19 11:39:34.789] [INFO] Successfully loaded model for engine 'qwen2.5-0.5b-instruct'
[2025-09-19 11:39:34.790] [INFO] Successfully added and loaded engine with ID 'qwen2.5-0.5b-instruct'. Model: D:\Works\Genta\codes\kolosal-agent\models\qwen2.5-0.5b-instruct-q4_k_m.gguf
[2025-09-19 11:39:34.790] [INFO] Model 'qwen2.5-0.5b-instruct' already exists in configuration, updating it
[2025-09-19 11:39:34.791] [INFO] Updated model 'qwen2.5-0.5b-instruct' in configuration
[2025-09-19 11:39:34.791] [INFO] About to save configuration for model 'qwen2.5-0.5b-instruct'
[2025-09-19 11:39:34.791] [INFO] Current config file path in NodeManager: 'C:\Users\Evint\AppData\Roaming\Kolosal\config.yaml'
[2025-09-19 11:39:34.792] [INFO] ServerConfig instance address during model save: 3546093664
[2025-09-19 11:39:34.793] [INFO] saveToCurrentFile called. currentConfigFilePath: 'C:\Users\Evint\AppData\Roaming\Kolosal\config.yaml'
[2025-09-19 11:39:34.793] [INFO] ServerConfig instance address: 140710969677920
[2025-09-19 11:39:34.793] [INFO] Saving to current config file: C:\Users\Evint\AppData\Roaming\Kolosal\config.yaml
[2025-09-19 11:39:34.802] [INFO] Successfully saved model 'qwen2.5-0.5b-instruct' to configuration file
[2025-09-19 11:39:34.803] [INFO] Model 'qwen2.5-0.5b-instruct' loaded successfully
[2025-09-19 11:39:34.803] [INFO] Loading LLM model 'qwen2.5-0.5b-instruct' at startup (load_immediately=true, engine=llama-vulkan)
[2025-09-19 11:39:34.804] [INFO] Engine 'qwen2.5-0.5b-instruct' already exists during startup, skipping load
[2025-09-19 11:39:34.804] [INFO] Model 'qwen2.5-0.5b-instruct' loaded successfully
[2025-09-19 11:40:04.707] [INFO] Shutting down server
[2025-09-19 11:40:04.707] [INFO] Stopping all downloads and waiting for threads to finish...
[2025-09-19 11:40:04.707] [INFO] Cancelling all active downloads before shutdown...
[2025-09-19 11:40:04.708] [INFO] No download threads to wait for
[2025-09-19 11:40:04.709] [INFO] Shutting down HTTP server
[2025-09-19 11:40:04.709] [INFO] Stopping server
[2025-09-19 11:40:04.709] [ERROR] Accept failed
[2025-09-19 11:40:04.710] [INFO] Server main loop exited
[2025-09-19 11:40:04.710] [INFO] Server shutdown complete
[2025-09-19 11:40:04.771] [INFO] NodeManager shutting down.
[2025-09-19 11:40:04.771] [INFO] Autoscaling thread stopped.
[2025-09-19 11:40:04.772] [INFO] Unloading engine ID 'qwen3-0.6b:UD-Q4_K_XL' during shutdown.
[2025-09-19 16:00:58.897] [INFO] Logger configured - Level: INFO, Quiet: false, Details: true
[2025-09-19 16:00:58.899] [INFO] Initializing server on 127.0.0.1:8081 with idle timeout: 60 seconds
[2025-09-19 16:00:58.899] [INFO] NodeManager initialized with idle timeout: 60 seconds.
[2025-09-19 16:00:58.900] [INFO] Configured inference engine: llama-cpu at C:\ProgramData\Kolosal\bin\llama-cpu.dll
[2025-09-19 16:00:58.933] [INFO] Successfully loaded inference engine: llama-cpu
[2025-09-19 16:00:58.933] [INFO] Auto-loaded inference engine: llama-cpu
[2025-09-19 16:00:58.933] [INFO] Configured inference engine: llama-vulkan at C:\ProgramData\Kolosal\bin\llama-vulkan.dll
[2025-09-19 16:00:58.933] [INFO] Engine configuration complete. Configured 2 inference engines.
[2025-09-19 16:00:58.933] [INFO] Configured 2 inference engines:
[2025-09-19 16:00:58.934] [INFO]   - llama-cpu: CPU-based inference engine for GGUF models (loaded)
[2025-09-19 16:00:58.934] [INFO]   - llama-vulkan: Vulkan GPU acceleration engine for GGUF models (available)
[2025-09-19 16:00:58.934] [INFO] Rate limiter initialized with default config - Max requests: 100, Window: 60 seconds, Enabled: true
[2025-09-19 16:00:58.934] [INFO] CORS configuration updated - Enabled: true, Origins: 1, Methods: 7, Headers: 5
[2025-09-19 16:00:58.934] [INFO] Authentication middleware initialized with default configuration
[2025-09-19 16:00:58.934] [INFO] Autoscaling thread started.
[2025-09-19 16:00:58.935] [INFO] Server initialized and listening on 127.0.0.1:8081
[2025-09-19 16:00:58.935] [INFO] Registering routes
[2025-09-19 16:00:58.935] [INFO] ModelsRoute initialized
[2025-09-19 16:00:58.935] [INFO] Auth config route initialized
[2025-09-19 16:00:58.935] [INFO] EmbeddingRoute initialized with completion monitoring
[2025-09-19 16:00:58.935] [INFO] DocumentsRoute initialized
[2025-09-19 16:00:58.936] [INFO] ChunkingService initialized
[2025-09-19 16:00:58.936] [INFO] ChunkingRoute initialized
[2025-09-19 16:00:58.936] [INFO] Routes registered successfully
[2025-09-19 16:00:58.936] [INFO] Rate limiter configuration updated - Max requests: 100, Window: 60 seconds, Enabled: true
[2025-09-19 16:00:58.936] [INFO] Starting server main loop
[2025-09-19 16:00:58.936] [INFO] Server entering main loop with concurrent request handling
[2025-09-19 16:00:58.936] [INFO] CORS configuration updated - Enabled: true, Origins: 1, Methods: 7, Headers: 5
[2025-09-19 16:00:58.936] [INFO] API key configuration updated - Enabled: true, Required: false, Keys count: 0
[2025-09-19 16:00:58.936] [INFO] Authentication configured - Rate Limit: enabled, CORS: enabled, API Keys: optional (0 keys)
[2025-09-19 16:00:58.936] [INFO] Metrics functionality not yet implemented
[2025-09-19 16:00:58.937] [INFO] System metrics monitoring enabled
[2025-09-19 16:00:58.937] [INFO] Loading LLM model 'qwen3-0.6b:UD-Q4_K_XL' at startup (load_immediately=true, engine=llama-vulkan)
[2025-09-19 16:00:58.937] [INFO] Validating model file for engine 'qwen3-0.6b:UD-Q4_K_XL': D:\Works\Genta\codes\kolosal-agent\models\qwen2.5-0.5b-instruct-q4_k_m.gguf
[2025-09-19 16:00:58.937] [INFO] Local model file found. Size: 468.64 MB
[2025-09-19 16:00:58.937] [INFO] Creating llama-vulkan inference engine for ID 'qwen3-0.6b:UD-Q4_K_XL'
[2025-09-19 16:00:58.937] [INFO] Loading llama-vulkan inference engine plugin...
[2025-09-19 16:00:58.971] [INFO] Successfully loaded inference engine: llama-vulkan
[2025-09-19 16:00:58.971] [INFO] Successfully loaded llama-vulkan inference engine plugin
[2025-09-19 16:00:58.971] [INFO] Creating inference engine instance...
[2025-09-19 16:00:58.971] [INFO] Loading model for engine 'qwen3-0.6b:UD-Q4_K_XL' from path: D:\Works\Genta\codes\kolosal-agent\models\qwen2.5-0.5b-instruct-q4_k_m.gguf
[2025-09-19 16:01:01.536] [INFO] Successfully loaded model for engine 'qwen3-0.6b:UD-Q4_K_XL'
[2025-09-19 16:01:01.537] [INFO] Successfully added and loaded engine with ID 'qwen3-0.6b:UD-Q4_K_XL'. Model: D:\Works\Genta\codes\kolosal-agent\models\qwen2.5-0.5b-instruct-q4_k_m.gguf
[2025-09-19 16:01:01.537] [INFO] Model 'qwen3-0.6b:UD-Q4_K_XL' already exists in configuration, updating it
[2025-09-19 16:01:01.537] [INFO] Updated model 'qwen3-0.6b:UD-Q4_K_XL' in configuration
[2025-09-19 16:01:01.537] [INFO] About to save configuration for model 'qwen3-0.6b:UD-Q4_K_XL'
[2025-09-19 16:01:01.538] [INFO] Current config file path in NodeManager: 'C:\Users\Evint\AppData\Roaming\Kolosal\config.yaml'
[2025-09-19 16:01:01.538] [INFO] ServerConfig instance address during model save: 1683512720
[2025-09-19 16:01:01.538] [INFO] saveToCurrentFile called. currentConfigFilePath: 'C:\Users\Evint\AppData\Roaming\Kolosal\config.yaml'
[2025-09-19 16:01:01.538] [INFO] ServerConfig instance address: 140726286966160
[2025-09-19 16:01:01.539] [INFO] Saving to current config file: C:\Users\Evint\AppData\Roaming\Kolosal\config.yaml
[2025-09-19 16:01:01.540] [INFO] Successfully saved model 'qwen3-0.6b:UD-Q4_K_XL' to configuration file
[2025-09-19 16:01:01.540] [INFO] Model 'qwen3-0.6b:UD-Q4_K_XL' loaded successfully
[2025-09-19 16:01:01.540] [INFO] Loading LLM model 'qwen2.5-0.5b-instruct' at startup (load_immediately=true, engine=llama-vulkan)
[2025-09-19 16:01:01.540] [INFO] Validating model file for engine 'qwen2.5-0.5b-instruct': D:\Works\Genta\codes\kolosal-agent\models\qwen2.5-0.5b-instruct-q4_k_m.gguf
[2025-09-19 16:01:01.541] [INFO] Local model file found. Size: 468.64 MB
[2025-09-19 16:01:01.541] [INFO] Creating llama-vulkan inference engine for ID 'qwen2.5-0.5b-instruct'
[2025-09-19 16:01:01.541] [INFO] Creating inference engine instance...
[2025-09-19 16:01:01.541] [INFO] Loading model for engine 'qwen2.5-0.5b-instruct' from path: D:\Works\Genta\codes\kolosal-agent\models\qwen2.5-0.5b-instruct-q4_k_m.gguf
[2025-09-19 16:01:02.141] [INFO] Successfully loaded model for engine 'qwen2.5-0.5b-instruct'
[2025-09-19 16:01:02.141] [INFO] Successfully added and loaded engine with ID 'qwen2.5-0.5b-instruct'. Model: D:\Works\Genta\codes\kolosal-agent\models\qwen2.5-0.5b-instruct-q4_k_m.gguf
[2025-09-19 16:01:02.141] [INFO] Model 'qwen2.5-0.5b-instruct' already exists in configuration, updating it
[2025-09-19 16:01:02.142] [INFO] Updated model 'qwen2.5-0.5b-instruct' in configuration
[2025-09-19 16:01:02.142] [INFO] About to save configuration for model 'qwen2.5-0.5b-instruct'
[2025-09-19 16:01:02.142] [INFO] Current config file path in NodeManager: 'C:\Users\Evint\AppData\Roaming\Kolosal\config.yaml'
[2025-09-19 16:01:02.142] [INFO] ServerConfig instance address during model save: 1683512720
[2025-09-19 16:01:02.143] [INFO] saveToCurrentFile called. currentConfigFilePath: 'C:\Users\Evint\AppData\Roaming\Kolosal\config.yaml'
[2025-09-19 16:01:02.143] [INFO] ServerConfig instance address: 140726286966160
[2025-09-19 16:01:02.143] [INFO] Saving to current config file: C:\Users\Evint\AppData\Roaming\Kolosal\config.yaml
[2025-09-19 16:01:02.144] [INFO] Successfully saved model 'qwen2.5-0.5b-instruct' to configuration file
[2025-09-19 16:01:02.145] [INFO] Model 'qwen2.5-0.5b-instruct' loaded successfully
[2025-09-19 16:01:02.145] [INFO] Loading LLM model 'qwen2.5-0.5b-instruct' at startup (load_immediately=true, engine=llama-vulkan)
[2025-09-19 16:01:02.145] [INFO] Engine 'qwen2.5-0.5b-instruct' already exists during startup, skipping load
[2025-09-19 16:01:02.146] [INFO] Model 'qwen2.5-0.5b-instruct' loaded successfully
[2025-09-19 16:01:22.393] [INFO] Shutting down server
[2025-09-19 16:01:22.393] [INFO] Stopping all downloads and waiting for threads to finish...
[2025-09-19 16:01:22.394] [INFO] Cancelling all active downloads before shutdown...
[2025-09-19 16:01:22.394] [INFO] No download threads to wait for
[2025-09-19 16:01:22.394] [INFO] Shutting down HTTP server
[2025-09-19 16:01:22.394] [INFO] Stopping server
[2025-09-19 16:01:22.395] [ERROR] Accept failed
[2025-09-19 16:01:22.395] [INFO] Server shutdown complete
